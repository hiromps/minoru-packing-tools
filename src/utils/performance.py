import time
import functools
import streamlit as st
from typing import Any, Callable, Dict, List
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio


class PerformanceMonitor:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.metrics = {}
        self.logger = logging.getLogger(__name__)
    
    def time_function(self, func_name: str = None):
        """é–¢æ•°å®Ÿè¡Œæ™‚é–“ã‚’æ¸¬å®šã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
        def decorator(func: Callable) -> Callable:
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                name = func_name or f"{func.__module__}.{func.__name__}"
                start_time = time.time()
                
                try:
                    result = func(*args, **kwargs)
                    execution_time = time.time() - start_time
                    
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                    if name not in self.metrics:
                        self.metrics[name] = []
                    self.metrics[name].append(execution_time)
                    
                    # ãƒ­ã‚°å‡ºåŠ›
                    self.logger.info(f"â±ï¸ {name}: {execution_time:.3f}s")
                    
                    # é…ã„å‡¦ç†ã¸ã®è­¦å‘Šï¼ˆ1ç§’ä»¥ä¸Šï¼‰
                    if execution_time > 1.0:
                        self.logger.warning(f"ğŸŒ Slow operation detected: {name} took {execution_time:.3f}s")
                    
                    return result
                    
                except Exception as e:
                    execution_time = time.time() - start_time
                    self.logger.error(f"âŒ {name} failed after {execution_time:.3f}s: {str(e)}")
                    raise
                    
            return wrapper
        return decorator
    
    def get_performance_report(self) -> Dict[str, Dict[str, float]]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = {}
        
        for func_name, times in self.metrics.items():
            if times:
                report[func_name] = {
                    'avg_time': sum(times) / len(times),
                    'min_time': min(times),
                    'max_time': max(times),
                    'total_calls': len(times),
                    'total_time': sum(times)
                }
        
        return report


class CacheManager:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, max_size: int = 1000):
        self.cache = {}
        self.access_times = {}
        self.max_size = max_size
        self.logger = logging.getLogger(__name__)
    
    def get(self, key: str) -> Any:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        if key in self.cache:
            self.access_times[key] = time.time()
            self.logger.debug(f"ğŸ¯ Cache hit: {key}")
            return self.cache[key]
        
        self.logger.debug(f"ğŸ’¨ Cache miss: {key}")
        return None
    
    def set(self, key: str, value: Any, ttl: int = 3600):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if len(self.cache) >= self.max_size:
            self._evict_oldest()
        
        self.cache[key] = {
            'value': value,
            'expires_at': time.time() + ttl,
            'created_at': time.time()
        }
        self.access_times[key] = time.time()
        self.logger.debug(f"ğŸ’¾ Cache set: {key} (TTL: {ttl}s)")
    
    def _evict_oldest(self):
        """æœ€ã‚‚å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤"""
        if not self.access_times:
            return
        
        oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
        self.delete(oldest_key)
        self.logger.debug(f"ğŸ—‘ï¸ Cache evicted: {oldest_key}")
    
    def delete(self, key: str):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤"""
        self.cache.pop(key, None)
        self.access_times.pop(key, None)
    
    def clear_expired(self):
        """æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤"""
        current_time = time.time()
        expired_keys = []
        
        for key, data in self.cache.items():
            if current_time > data['expires_at']:
                expired_keys.append(key)
        
        for key in expired_keys:
            self.delete(key)
            self.logger.debug(f"â° Expired cache removed: {key}")
        
        return len(expired_keys)
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’å–å¾—"""
        current_time = time.time()
        expired_count = sum(1 for data in self.cache.values() 
                          if current_time > data['expires_at'])
        
        return {
            'total_entries': len(self.cache),
            'expired_entries': expired_count,
            'valid_entries': len(self.cache) - expired_count,
            'cache_usage': f"{len(self.cache)}/{self.max_size}",
            'memory_usage_mb': self._estimate_memory_usage()
        }
    
    def _estimate_memory_usage(self) -> float:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¨å®šï¼ˆMBï¼‰"""
        import sys
        total_size = 0
        
        for key, data in self.cache.items():
            total_size += sys.getsizeof(key)
            total_size += sys.getsizeof(data)
            total_size += sys.getsizeof(data['value'])
        
        return total_size / (1024 * 1024)  # MB


class ParallelProcessor:
    """ä¸¦åˆ—å‡¦ç†ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.logger = logging.getLogger(__name__)
    
    def process_parallel(self, func: Callable, items: List[Any], 
                        chunk_size: int = None) -> List[Any]:
        """ä¸¦åˆ—å‡¦ç†ã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ"""
        if not items:
            return []
        
        # å°ã•ãªãƒªã‚¹ãƒˆã¯ä¸¦åˆ—åŒ–ã—ãªã„
        if len(items) < 4:
            return [func(item) for item in items]
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºè‡ªå‹•è¨ˆç®—
        if chunk_size is None:
            chunk_size = max(1, len(items) // self.max_workers)
        
        results = []
        start_time = time.time()
        
        try:
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ
                future_to_item = {
                    executor.submit(func, item): item 
                    for item in items
                }
                
                for future in as_completed(future_to_item):
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        item = future_to_item[future]
                        self.logger.error(f"âŒ Parallel task failed for {item}: {str(e)}")
                        results.append(None)
            
            execution_time = time.time() - start_time
            self.logger.info(f"âš¡ Parallel processing completed: {len(items)} items in {execution_time:.3f}s")
            
        except Exception as e:
            self.logger.error(f"âŒ Parallel processing failed: {str(e)}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šé †æ¬¡å‡¦ç†
            results = [func(item) for item in items]
        
        return results


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
performance_monitor = PerformanceMonitor()
cache_manager = CacheManager()
parallel_processor = ParallelProcessor()


def cached_function(ttl: int = 3600, key_func: Callable = None):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãé–¢æ•°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                cache_key = f"{func.__name__}_{hash(str(args) + str(sorted(kwargs.items())))}"
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—è©¦è¡Œ
            cached_result = cache_manager.get(cache_key)
            if cached_result is not None:
                return cached_result['value']
            
            # é–¢æ•°å®Ÿè¡Œ
            result = func(*args, **kwargs)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            cache_manager.set(cache_key, result, ttl)
            
            return result
        return wrapper
    return decorator


@st.cache_data(ttl=3600)
def streamlit_cached_calculation(func_name: str, *args, **kwargs):
    """Streamlitã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨ã—ãŸè¨ˆç®—"""
    # ã“ã®é–¢æ•°ã¯å…·ä½“çš„ãªè¨ˆç®—é–¢æ•°ã‚’ãƒ©ãƒƒãƒ—ã—ã¦ä½¿ç”¨
    pass